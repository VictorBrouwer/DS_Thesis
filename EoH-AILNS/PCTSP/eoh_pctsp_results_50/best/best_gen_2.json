{
  "algorithm": "Modified version of: Initial PCTSP repair operator generated from scratch",
  "code": "def llm_repair(state: 'PCTSPSolution', rng, **kwargs) -> 'PCTSPSolution':\n    \"\"\"\n    Repair operator for the Price Collecting Travelling Salesman Problem (PCTSP) using ALNS.\n    \"\"\"\n    unvisited = state.unvisited[:]\n\n    # Sort unvisited nodes by prize-to-penalty ratio (high to low)\n    unvisited.sort(key=lambda node: DATA.prizes[node] / DATA.penalties[node], reverse=True)\n\n    for node in unvisited:\n        state.opt_insert(node)\n\n    # Ensure feasibility\n    while not state.is_feasible():\n        # Remove node with the lowest (prize - penalty) / cost ratio\n        worst_node = None\n        worst_ratio = float('inf')\n        for node in state.tour:\n            prize = DATA.prizes[node]\n            penalty = DATA.penalties[node]\n            idx = state.tour.index(node)\n            if len(state.tour) > 1:\n                prev_node = state.tour[idx - 1] if idx > 0 else state.tour[-1]\n                next_node = state.tour[idx + 1] if idx < len(state.tour) - 1 else state.tour[0]\n                cost = np.linalg.norm(DATA.locations[node] - DATA.locations[prev_node]) + \\\n                       np.linalg.norm(DATA.locations[node] - DATA.locations[next_node])\n            else:\n                cost = 2 * np.linalg.norm(DATA.locations[node] - DATA.depot)\n\n            ratio = (prize - penalty) / cost if cost > 0 else float('inf')\n            if ratio < worst_ratio:\n                worst_ratio = ratio\n                worst_node = node\n\n        if worst_node is not None:\n            state.remove(worst_node)\n            state.unvisited.append(worst_node)\n            \n    # Try to improve by swapping nodes\n    for i in range(len(state.tour)):\n        for j in range(len(state.unvisited)):\n            node_in = state.unvisited[j]\n            node_out = state.tour[i]\n            \n            # Evaluate the potential gain from swapping\n            prize_diff = DATA.prizes[node_in] - DATA.prizes[node_out]\n            penalty_diff = DATA.penalties[node_out] - DATA.penalties[node_in]\n            \n            # Rough cost estimation (can be made more precise)\n            if len(state.tour) > 1:\n                idx = state.tour.index(node_out)\n                prev_node = state.tour[idx - 1] if idx > 0 else state.tour[-1]\n                next_node = state.tour[idx + 1] if idx < len(state.tour) - 1 else state.tour[0]\n                cost_diff = (np.linalg.norm(DATA.locations[node_in] - DATA.locations[prev_node]) + \\\n                             np.linalg.norm(DATA.locations[node_in] - DATA.locations[next_node]) - \\\n                             np.linalg.norm(DATA.locations[node_out] - DATA.locations[prev_node]) - \\\n                             np.linalg.norm(DATA.locations[node_out] - DATA.locations[next_node]))\n            else:\n                cost_diff = (2 * np.linalg.norm(DATA.locations[node_in] - DATA.depot) - \\\n                            2 * np.linalg.norm(DATA.locations[node_out] - DATA.depot))\n            \n            gain = prize_diff - penalty_diff - cost_diff\n            \n            if gain > 0:\n                state.remove(node_out)\n                state.unvisited.append(node_out)\n                state.opt_insert(node_in)\n                state.unvisited.remove(node_in)\n                break # Only swap one node per iteration to avoid instability\n\n    return state",
  "objective": 11.819084979153438,
  "gap": -20.279899573513923,
  "runtime": 60.02359390258789,
  "timestamp": "2025-06-13 14:23:54",
  "feasible": true,
  "instance1_objective": 6.010238998533892,
  "instance2_objective": 5.808845980619546,
  "instance1_gap": -25.20325362902713,
  "instance2_gap": -15.356545518000717,
  "instance1_feasible": true,
  "instance2_feasible": true,
  "tour_length": 100,
  "prize_collected": 3.6335959601441985,
  "strategy": "m1",
  "generation": 1
}